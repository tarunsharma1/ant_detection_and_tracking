#!/usr/bin/env python3
"""
Verify Cluster Indexing Consistency

This script checks if cluster labels are consistent between:
1. The CSV file generated by clustering_trajectories.py
2. The visualization in visualize_clusters()
3. The analysis in distribution_of_clusters_over_time.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

def verify_cluster_indexing(csv_file):
    """
    Verify cluster indexing consistency.
    
    Parameters
    ----------
    csv_file : str
        Path to the comprehensive_trajectory_analysis.csv file
    """
    print("üîç VERIFYING CLUSTER INDEXING CONSISTENCY")
    print("=" * 60)
    
    if not os.path.exists(csv_file):
        print(f"‚ùå File not found: {csv_file}")
        return
    
    # Load the data
    print(f"Loading data from {csv_file}...")
    df = pd.read_csv(csv_file)
    print(f"‚úÖ Loaded {len(df):,} trajectories")
    
    # Check cluster label consistency
    print(f"\nüìä CLUSTER LABEL ANALYSIS:")
    print(f"   Unique cluster labels: {sorted(df['cluster_label'].unique())}")
    print(f"   Number of clusters: {len(df['cluster_label'].unique())}")
    print(f"   Cluster label type: {type(df['cluster_label'].iloc[0])}")
    
    # Check for any non-integer or negative labels
    unique_labels = df['cluster_label'].unique()
    print(f"\nüîç LABEL VALIDATION:")
    
    issues = []
    
    # Check for non-integer labels
    non_integer_labels = [label for label in unique_labels if not isinstance(label, (int, np.integer))]
    if non_integer_labels:
        issues.append(f"Non-integer labels found: {non_integer_labels}")
    
    # Check for negative labels (except -1 for noise in DBSCAN)
    negative_labels = [label for label in unique_labels if label < 0 and label != -1]
    if negative_labels:
        issues.append(f"Unexpected negative labels: {negative_labels}")
    
    # Check for gaps in sequence
    sorted_labels = sorted([label for label in unique_labels if label >= 0])
    if sorted_labels:
        expected_sequence = list(range(len(sorted_labels)))
        if sorted_labels != expected_sequence:
            issues.append(f"Non-sequential labels: {sorted_labels} (expected: {expected_sequence})")
    
    # Check for missing 0
    if 0 not in unique_labels:
        issues.append("Missing cluster 0 (should start from 0)")
    
    if issues:
        print("   ‚ùå ISSUES FOUND:")
        for issue in issues:
            print(f"      - {issue}")
    else:
        print("   ‚úÖ All cluster labels are valid and consistent")
    
    # Analyze cluster distribution
    print(f"\nüìà CLUSTER DISTRIBUTION:")
    cluster_counts = df['cluster_label'].value_counts().sort_index()
    for cluster, count in cluster_counts.items():
        percentage = (count / len(df)) * 100
        print(f"   Cluster {cluster}: {count:,} trajectories ({percentage:.1f}%)")
    
    # Check for any trajectories with missing cluster labels
    missing_labels = df['cluster_label'].isna().sum()
    if missing_labels > 0:
        print(f"   ‚ö†Ô∏è  {missing_labels} trajectories with missing cluster labels")
    
    # Verify trajectory index consistency
    print(f"\nüîó TRAJECTORY INDEX CONSISTENCY:")
    print(f"   Trajectory index range: {df['trajectory_index'].min()} to {df['trajectory_index'].max()}")
    print(f"   Expected range: 0 to {len(df)-1}")
    
    if df['trajectory_index'].min() == 0 and df['trajectory_index'].max() == len(df)-1:
        print("   ‚úÖ Trajectory indices are consistent")
    else:
        print("   ‚ùå Trajectory indices are inconsistent")
    
    # Check for duplicate trajectory indices
    duplicate_indices = df['trajectory_index'].duplicated().sum()
    if duplicate_indices > 0:
        print(f"   ‚ùå {duplicate_indices} duplicate trajectory indices found")
    else:
        print("   ‚úÖ No duplicate trajectory indices")
    
    # Summary
    print(f"\nüìã SUMMARY:")
    if not issues and missing_labels == 0 and duplicate_indices == 0:
        print("   ‚úÖ Cluster indexing is CONSISTENT between files")
        print("   ‚úÖ All cluster labels are valid integers starting from 0")
        print("   ‚úÖ No missing or duplicate data")
    else:
        print("   ‚ùå Cluster indexing has ISSUES that need to be fixed")
        print("   üí° Check the clustering algorithm implementation")
    
    return len(issues) == 0 and missing_labels == 0 and duplicate_indices == 0

def plot_cluster_verification(df, max_trajectories_per_cluster=50, output_dir='cluster_verification_plots'):
    """
    Create visual verification plots showing trajectories from each cluster.
    
    Parameters
    ----------
    df : pd.DataFrame
        Trajectory data with cluster labels
    max_trajectories_per_cluster : int
        Maximum number of trajectories to plot per cluster
    output_dir : str
        Directory to save verification plots
    """
    print(f"\nüé® CREATING VISUAL VERIFICATION PLOTS")
    print("=" * 50)
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Get unique clusters
    clusters = sorted(df['cluster_label'].unique())
    n_clusters = len(clusters)
    
    print(f"   Found {n_clusters} clusters: {clusters}")
    
    # Create subplot layout
    n_cols = min(3, n_clusters)
    n_rows = (n_clusters + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
    if n_clusters == 1:
        axes = [axes]
    elif n_rows == 1:
        axes = axes
    else:
        axes = axes.flatten()
    
    # Colors for different clusters
    colors = plt.cm.tab10(np.linspace(0, 1, n_clusters))
    
    for i, cluster_id in enumerate(clusters):
        if cluster_id == -1:  # Skip noise if present
            continue
            
        ax = axes[i] if i < len(axes) else axes[0]
        
        # Get trajectories for this cluster
        cluster_data = df[df['cluster_label'] == cluster_id]
        print(f"   Cluster {cluster_id}: {len(cluster_data):,} trajectories")
        
        # Sample trajectories for visualization
        if len(cluster_data) > max_trajectories_per_cluster:
            # Random sampling
            np.random.seed(42)
            sample_indices = np.random.choice(len(cluster_data), max_trajectories_per_cluster, replace=False)
            cluster_sample = cluster_data.iloc[sample_indices]
        else:
            cluster_sample = cluster_data
        
        # Plot feature distributions for this cluster
        color = colors[i]
        
        # Get feature columns (assuming they exist in the CSV)
        feature_columns = ['efficiency', 'loop_strength', 'circularity', 'avg_curvature', 
                          'pause_ratio', 'spatial_compactness', 'total_length', 'avg_speed']
        
        # Create a 2D scatter plot of two key features
        if 'efficiency' in cluster_sample.columns and 'loop_strength' in cluster_sample.columns:
            x_vals = cluster_sample['efficiency']
            y_vals = cluster_sample['loop_strength']
            ax.scatter(x_vals, y_vals, color=color, alpha=0.6, s=20, label=f'Cluster {cluster_id}')
            
            # Add cluster center
            center_x = x_vals.mean()
            center_y = y_vals.mean()
            ax.scatter(center_x, center_y, color=color, s=100, marker='x', linewidth=3)
            
            ax.set_xlabel('Efficiency')
            ax.set_ylabel('Loop Strength')
        else:
            # Fallback: plot trajectory index vs a feature
            if 'trajectory_index' in cluster_sample.columns and len(feature_columns) > 0:
                available_feature = None
                for feat in feature_columns:
                    if feat in cluster_sample.columns:
                        available_feature = feat
                        break
                
                if available_feature:
                    x_vals = cluster_sample['trajectory_index']
                    y_vals = cluster_sample[available_feature]
                    ax.scatter(x_vals, y_vals, color=color, alpha=0.6, s=20)
                    ax.set_xlabel('Trajectory Index')
                    ax.set_ylabel(available_feature)
                else:
                    # Last resort: just plot points
                    ax.scatter(range(len(cluster_sample)), [0]*len(cluster_sample), 
                              color=color, alpha=0.6, s=20)
                    ax.set_xlabel('Sample Index')
                    ax.set_ylabel('Placeholder')
            else:
                # Last resort: just plot points
                ax.scatter(range(len(cluster_sample)), [0]*len(cluster_sample), 
                          color=color, alpha=0.6, s=20)
                ax.set_xlabel('Sample Index')
                ax.set_ylabel('Placeholder')
        
        # Customize subplot
        ax.set_title(f'Cluster {cluster_id}\n({len(cluster_data):,} total, {len(cluster_sample)} shown)', 
                    fontsize=12, fontweight='bold')
        ax.grid(True, alpha=0.3)
    
    # Hide unused subplots
    for i in range(n_clusters, len(axes)):
        axes[i].set_visible(False)
    
    plt.suptitle('Cluster Verification: Trajectory Distributions', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # Save the plot
    output_file = os.path.join(output_dir, 'cluster_verification_plot.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Verification plot saved to {output_file}")
    
    plt.show()
    
    # Create a summary plot showing cluster sizes
    create_cluster_size_plot(df, output_dir)
    
    # Create feature comparison plots
    create_feature_comparison_plots(df, output_dir)
    
    return output_file

def create_cluster_size_plot(df, output_dir):
    """
    Create a plot showing cluster size distribution.
    """
    print(f"   üìä Creating cluster size distribution plot...")
    
    # Calculate cluster sizes
    cluster_sizes = df['cluster_label'].value_counts().sort_index()
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Bar plot of cluster sizes
    clusters = cluster_sizes.index
    sizes = cluster_sizes.values
    colors = plt.cm.tab10(np.linspace(0, 1, len(clusters)))
    
    bars = ax1.bar(clusters, sizes, color=colors, alpha=0.7, edgecolor='black', linewidth=1)
    ax1.set_xlabel('Cluster ID', fontsize=12)
    ax1.set_ylabel('Number of Trajectories', fontsize=12)
    ax1.set_title('Cluster Size Distribution', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar, size in zip(bars, sizes):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{size:,}', ha='center', va='bottom', fontsize=10)
    
    # Pie chart of cluster proportions
    percentages = (sizes / sizes.sum()) * 100
    wedges, texts, autotexts = ax2.pie(sizes, labels=[f'Cluster {c}\n({p:.1f}%)' for c, p in zip(clusters, percentages)],
                                      colors=colors, autopct='%1.1f%%', startangle=90)
    ax2.set_title('Cluster Proportion Distribution', fontsize=14, fontweight='bold')
    
    # Make percentage text smaller
    for autotext in autotexts:
        autotext.set_fontsize(9)
        autotext.set_color('white')
        autotext.set_weight('bold')
    
    plt.tight_layout()
    
    # Save cluster size plot
    size_plot_file = os.path.join(output_dir, 'cluster_size_distribution.png')
    plt.savefig(size_plot_file, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Cluster size plot saved to {size_plot_file}")
    
    plt.show()
    
    return size_plot_file

def create_feature_comparison_plots(df, output_dir):
    """
    Create plots comparing features across clusters.
    """
    print(f"   üìä Creating feature comparison plots...")
    
    # Get feature columns
    feature_columns = ['efficiency', 'loop_strength', 'circularity', 'avg_curvature', 
                      'pause_ratio', 'spatial_compactness', 'total_length', 'avg_speed']
    
    # Filter to only existing columns
    available_features = [col for col in feature_columns if col in df.columns]
    
    if len(available_features) == 0:
        print(f"      ‚ö†Ô∏è  No feature columns found for comparison")
        return
    
    # Create subplots for feature comparison
    n_features = len(available_features)
    n_cols = min(3, n_features)
    n_rows = (n_features + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
    if n_features == 1:
        axes = [axes]
    elif n_rows == 1:
        axes = axes
    else:
        axes = axes.flatten()
    
    # Get unique clusters
    clusters = sorted(df['cluster_label'].unique())
    colors = plt.cm.tab10(np.linspace(0, 1, len(clusters)))
    
    for i, feature in enumerate(available_features):
        ax = axes[i] if i < len(axes) else axes[0]
        
        # Create box plots for each cluster
        cluster_data = []
        cluster_labels = []
        
        for cluster_id in clusters:
            cluster_values = df[df['cluster_label'] == cluster_id][feature].dropna()
            if len(cluster_values) > 0:
                cluster_data.append(cluster_values)
                cluster_labels.append(f'Cluster {cluster_id}')
        
        if cluster_data:
            # Create box plot
            box_plot = ax.boxplot(cluster_data, labels=cluster_labels, patch_artist=True)
            
            # Color the boxes
            for patch, color in zip(box_plot['boxes'], colors[:len(cluster_data)]):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
            
            ax.set_title(f'{feature.replace("_", " ").title()}', fontsize=12, fontweight='bold')
            ax.set_ylabel('Feature Value')
            ax.grid(True, alpha=0.3)
            
            # Rotate x-axis labels if needed
            if len(cluster_labels) > 3:
                ax.tick_params(axis='x', rotation=45)
    
    # Hide unused subplots
    for i in range(n_features, len(axes)):
        axes[i].set_visible(False)
    
    plt.suptitle('Feature Comparison Across Clusters', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # Save feature comparison plot
    feature_plot_file = os.path.join(output_dir, 'feature_comparison_across_clusters.png')
    plt.savefig(feature_plot_file, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Feature comparison plot saved to {feature_plot_file}")
    
    plt.show()
    
    return feature_plot_file

def main():
    """
    Main function to verify cluster indexing.
    """
    # Configuration - update this path as needed
    csv_file = '/home/tarun/Desktop/plots_for_committee_meeting/trajectory_clustering/beer-tree-08-01-2024_to_08-10-2024/comprehensive_trajectory_analysis.csv'
    
    if not os.path.exists(csv_file):
        print(f"‚ùå CSV file not found: {csv_file}")
        print("Please update the csv_file path in the script")
        return
    
    # Verify indexing
    is_consistent = verify_cluster_indexing(csv_file)
    
    # Load data for visual verification
    print(f"\nüìä LOADING DATA FOR VISUAL VERIFICATION")
    df = pd.read_csv(csv_file)
    
    # Create visual verification plots
    plot_cluster_verification(df, max_trajectories_per_cluster=50)
    
    if is_consistent:
        print(f"\nüéâ VERIFICATION COMPLETE: Indexing is consistent!")
    else:
        print(f"\n‚ö†Ô∏è  VERIFICATION COMPLETE: Issues found that need attention")

if __name__ == "__main__":
    main()
